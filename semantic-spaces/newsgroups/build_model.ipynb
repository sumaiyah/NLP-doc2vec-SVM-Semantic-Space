{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train doc2ve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import sys\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "from collections import namedtuple\n",
    "import nltk\n",
    "from gensim.models.doc2vec import  LabeledSentence\n",
    "import sys\n",
    "from os import listdir\n",
    "\n",
    "NewsgroupDocument = namedtuple('NewsGroupDocument', 'words tags category')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print current epochs\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        # print('Epoch #{} start'.format(self.epoch))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.epoch == 0:\n",
    "            print('Epoch #{}'.format(self.epoch), end=' ')\n",
    "        else:\n",
    "            print('#{}'.format(self.epoch), end=' ')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, documents, labels, clean_param_str, model_name):\n",
    "        self.documents = documents\n",
    "        self.labels = labels\n",
    "        self.clean_param_str = clean_param_str\n",
    "        self.model_name = model_name\n",
    "        self.doc2vec_model = None\n",
    "        self.path_to_models = 'models/' # path to trained doc2vec models\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.tagged_docs = self.convert_to_doc2vec_format()\n",
    "        \n",
    "        self.build_and_train()\n",
    "        \n",
    "    # return docs in form expected by doc2vec i.e. list of tagged documents\n",
    "    def convert_to_doc2vec_format(self):\n",
    "        tagged_docs = []\n",
    "\n",
    "        for doc_id, doc_contents in enumerate(self.documents):\n",
    "            tagged_docs.append(NewsgroupDocument(doc_contents, [doc_id+1], self.labels[doc_id]))\n",
    "\n",
    "        return tagged_docs\n",
    "    \n",
    "    def train(self, parameters):\n",
    "        # initialise model\n",
    "        model = Doc2Vec(**parameters, callbacks=[EpochLogger()])\n",
    "        \n",
    "        print('training doc2vec model...', end=\"\") # -------------------\n",
    "        model.build_vocab(self.tagged_docs)\n",
    "        model.train(self.tagged_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "        # save model to disk\n",
    "        model.save(self.path_to_models + self.model_name)\n",
    "        \n",
    "        # write information about model to file\n",
    "        f = open('models/model_info.txt', 'a')\n",
    "        f.write(self.model_name + '\\n')\n",
    "        f.write(str(parameters) + '\\n')\n",
    "        f.write('clean: '+ self.clean_param_str) # how this doc2vec model was cleaned\n",
    "        f.close()\n",
    "        \n",
    "        print('\\ntrained model!', self.model_name) # -------------------\n",
    "        \n",
    "        self.doc2vec_model = model\n",
    "    \n",
    "    def build_and_train(self):\n",
    "        parameters=dict(dm=0,\n",
    "                    vector_size=100,\n",
    "                    epochs=20,\n",
    "                    min_count=4,\n",
    "                    workers=multiprocessing.cpu_count(),\n",
    "                    negative=5,\n",
    "                    hs=0,\n",
    "                    sample=0,\n",
    "                    )\n",
    "        \n",
    "        if self.model_name in listdir(self.path_to_models):\n",
    "            print(\"Overwrite danger! CHANGE MODEL NAME!\")\n",
    "        else:\n",
    "            self.train(parameters=parameters)\n",
    "           \n",
    "    # return a list of infered vectors of the documents\n",
    "    def infer_all_vectors(self):\n",
    "        X = []\n",
    "\n",
    "        model = Doc2Vec.load('models/' + self.model_name)\n",
    "        for doc in self.tagged_docs:\n",
    "            X.append(model.infer_vector(doc.words))\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
